{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-31T06:22:21.528294Z",
     "iopub.status.busy": "2022-07-31T06:22:21.527656Z",
     "iopub.status.idle": "2022-07-31T06:22:21.534740Z",
     "shell.execute_reply": "2022-07-31T06:22:21.533143Z",
     "shell.execute_reply.started": "2022-07-31T06:22:21.528249Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.004536Z",
     "start_time": "2025-01-18T00:20:44.002560Z"
    }
   },
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "import numpy as np"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Tensor的理解：\n",
    "    1.常数，scaler:0阶张量\n",
    "    2.向量,vector,1阶张量\n",
    "    3.矩阵,matrix:2阶张量\n",
    "    4.3阶张量\n",
    "# 2. 创建张量的方法：\n",
    "     1.使用列表创建Tensor\n",
    "     2.使用numpy数组创建Tensor\n",
    "     3.通过torch的API创建Tensor\n",
    "     \n",
    "# 3. 张量的方法和属性\n",
    "    1.tensor.item(),当tensor中只有一个元素可以用的时候\n",
    "    2.Tensor转为ndarray\n",
    "    3.形状修改，tensor.view((3, 4)), 类似numpy中的reshape,是一种浅拷贝\n",
    "    4.获取维数、转置、轴滚动。\n",
    "    5.在方法后加_，会原地修改，相当于Tensorflow里的inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 创建张量的方法："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T06:27:39.559996Z",
     "iopub.status.busy": "2022-07-31T06:27:39.559579Z",
     "iopub.status.idle": "2022-07-31T06:27:39.576433Z",
     "shell.execute_reply": "2022-07-31T06:27:39.575188Z",
     "shell.execute_reply.started": "2022-07-31T06:27:39.559963Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.027948Z",
     "start_time": "2025-01-18T00:20:44.021538Z"
    }
   },
   "source": [
    "# 1.使用列表创建Tensor\n",
    "t1 = torch.Tensor([1, 2, 3])\n",
    "print(t1)\n",
    "\"\"\"\n",
    "tensor([1., 2., 3.])\n",
    "\"\"\"\n",
    "\n",
    "# 2.使用numpy数组创建Tensor\n",
    "array1 = np.arange(12).reshape(3, 4)\n",
    "\n",
    "t2 = torch.Tensor(array1)\n",
    "print(t2)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": "t2[0:1,:] #切片",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.065337Z",
     "start_time": "2025-01-18T00:20:44.056949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2., 3.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "# 3.通过torch的API创建Tensor\n",
    "\"\"\"\n",
    "torch.empty(3,4)：创建3行四列的空的tensor,会用无用的数据进行填充\n",
    "torch.ones([3,4]):三行四列全为1的tensor\n",
    "torch.zeros([3,4]):三行四列全为0的tensor\n",
    "torch.rand([3,4]):三行四列随机值在[0,1]之间的值\n",
    "torch.randint(low = 0, high = 10, size = [3, 4]) 创建3*4的随机整数的Tensor，值区间：[low, high]\n",
    "torch.randn([3,4]) 均值为0，方差为1,3*4的tensor\n",
    "\"\"\"\n",
    "print(torch.empty(3,4))\n",
    "print(torch.ones([3,4]))\n",
    "print(torch.zeros([3,4]))\n",
    "print(torch.rand([3,4]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.078390Z",
     "start_time": "2025-01-18T00:20:44.066338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5753e-25,  1.3985e-42,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[0.2272, 0.2860, 0.5554, 0.2697],\n",
      "        [0.4107, 0.8601, 0.3235, 0.4400],\n",
      "        [0.6079, 0.2563, 0.8856, 0.5488]])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 张量的方法和属性"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T06:29:04.995479Z",
     "iopub.status.busy": "2022-07-31T06:29:04.995033Z",
     "iopub.status.idle": "2022-07-31T06:29:05.019150Z",
     "shell.execute_reply": "2022-07-31T06:29:05.017794Z",
     "shell.execute_reply.started": "2022-07-31T06:29:04.995441Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.082005Z",
     "start_time": "2025-01-18T00:20:44.078390Z"
    }
   },
   "source": [
    "# 1.tensor.item(),当tensor中只有一个元素可以用的时候\n",
    "a =torch.tensor(np.arange(1))\n",
    "print(a)\n",
    "print(a.item()) #只有一个元素的时候可以用,返回一个python的标量,不可以用于多个元素的tensor\n",
    "print('-'*50)\n",
    "\n",
    "print(torch.Tensor([[[1]]]).item()) #获取一个tensor中的元素值\n",
    "print('-'*50)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0], dtype=torch.int32)\n",
      "0\n",
      "--------------------------------------------------\n",
      "1.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "# 2.Tensor转为ndarray\n",
    "t2 = torch.Tensor([[3,4]])\n",
    "print(t2)\n",
    "print(t2.shape)\n",
    "print(t2.numpy()) #tensor转为ndarray\n",
    "print('-'*50)\n",
    "print(t2.shape) #获取形状\n",
    "print(t2.size()) #获取形状\n",
    "print(t2.size(1))  #获取某个维度的形状,维度后的张量切片  第1维有两列\n",
    "print(t2.size(0))   # 第0维有1行"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.090431Z",
     "start_time": "2025-01-18T00:20:44.082005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4.]])\n",
      "torch.Size([1, 2])\n",
      "[[3. 4.]]\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "t2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.098248Z",
     "start_time": "2025-01-18T00:20:44.090431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 4.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "#写一个ndarray\n",
    "array1 = np.array([[1,2,3],[4,5,6]])\n",
    "print(id(array1))\n",
    "array2=array1.reshape(3,2)\n",
    "print(id(array2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.107656Z",
     "start_time": "2025-01-18T00:20:44.105249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3055618326128\n",
      "3055618324880\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "array2[0,0]=100\n",
    "print(array1)\n",
    "print(array2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.114970Z",
     "start_time": "2025-01-18T00:20:44.108658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100   2   3]\n",
      " [  4   5   6]]\n",
      "[[100   2]\n",
      " [  3   4]\n",
      " [  5   6]]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "array1.ndim #获取维数"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.125179Z",
     "start_time": "2025-01-18T00:20:44.121972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "# 3.3.形状修改，tensor.view((3, 4)), 类似numpy中的reshape,是一种浅拷贝，仅仅形状发生改变,返回一个新的结果\n",
    "print(t2)\n",
    "t2 = torch.Tensor([[[3,4]]])\n",
    "print(t2.size())\n",
    "print(t2.view([1,2])) #[1,2]表示1行2列\n",
    "print(t2.view([2])) # 一维tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.136291Z",
     "start_time": "2025-01-18T00:20:44.132496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4.]])\n",
      "torch.Size([1, 1, 2])\n",
      "tensor([[3., 4.]])\n",
      "tensor([3., 4.])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.181221Z",
     "start_time": "2025-01-18T00:20:44.175381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "b=t2.view([2, -1]) # -1表示自动计算\n",
    "print(b)\n",
    "print('-'*50)\n",
    "print(t2) #t2的形状并没有发生改变\n",
    "# https://pytorch.org/docs/stable/tensor_view.html\n",
    "t2.untyped_storage().untyped().data_ptr() == b.untyped_storage().untyped().data_ptr() #判断两个tensor是否共享内存"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.],\n",
      "        [4.]])\n",
      "--------------------------------------------------\n",
      "tensor([[[3., 4.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "b[0,0]=100\n",
    "print(b)\n",
    "print(t2) #t2的形状并没有发生改变"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.191727Z",
     "start_time": "2025-01-18T00:20:44.181221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100.],\n",
      "        [  4.]])\n",
      "tensor([[[100.,   4.]]])\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "#3. 获取维数\n",
    "print(t2.dim())\n",
    "print(t2.size())\n",
    "\n",
    "#4.获取最大值\n",
    "print(t2.max())\n",
    "\n",
    "#5.转置\n",
    "t3 = torch.tensor([[1,3,4], [2,4,6]])\n",
    "print(t3)\n",
    "print(t3.t()) #转置\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T00:22:50.148881Z",
     "start_time": "2025-01-18T00:22:50.144463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "torch.Size([1, 1, 2])\n",
      "tensor(100.)\n",
      "tensor([[1, 3, 4],\n",
      "        [2, 4, 6]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [4, 6]])\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "source": [
    "# 交换轴,这里的permute和rollaxis功能类型\n",
    "t4 = torch.tensor(np.arange(24).reshape(2,3,4))\n",
    "print(t4.shape)\n",
    "print(\"-\"*50)\n",
    "print(t4.transpose(0,1).shape)#交换0轴和1轴\n",
    "print(\"-\"*50)\n",
    "print(t4.permute(1, 0, 2).shape)#交换0轴和1轴,功能同上\n",
    "print(\"-\"*50)\n",
    "print(t4.permute(1, 2, 0).shape)#变为了3*4*2\n",
    "print(\"-\"*50)\n",
    "print(t4.permute(2, 1, 0).shape)#变为了4*3*2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.205487Z",
     "start_time": "2025-01-18T00:20:44.201382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "--------------------------------------------------\n",
      "torch.Size([3, 2, 4])\n",
      "--------------------------------------------------\n",
      "torch.Size([3, 2, 4])\n",
      "--------------------------------------------------\n",
      "torch.Size([3, 4, 2])\n",
      "--------------------------------------------------\n",
      "torch.Size([4, 3, 2])\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "t4.dtype"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.212293Z",
     "start_time": "2025-01-18T00:20:44.209491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T06:30:31.128553Z",
     "iopub.status.busy": "2022-07-31T06:30:31.128150Z",
     "iopub.status.idle": "2022-07-31T06:30:31.140028Z",
     "shell.execute_reply": "2022-07-31T06:30:31.138517Z",
     "shell.execute_reply.started": "2022-07-31T06:30:31.128521Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.253082Z",
     "start_time": "2025-01-18T00:20:44.247780Z"
    }
   },
   "source": [
    "# 在方法后加_，会原地修改\n",
    "x = torch.tensor(np.arange(12).reshape(3,4),dtype = torch.int8)\n",
    "print(x)\n",
    "y= torch.ones([3,4], dtype = torch.int64)\n",
    "print(y)\n",
    "\n",
    "print('-'*50)\n",
    "x.sub_(y) # add_就地修改，不加下划线的会创建一个新的tensor来存储\n",
    "print(x)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]], dtype=torch.int8)\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]])\n",
      "--------------------------------------------------\n",
      "tensor([[-1,  0,  1,  2],\n",
      "        [ 3,  4,  5,  6],\n",
      "        [ 7,  8,  9, 10]], dtype=torch.int8)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "#tensor取值,和np完全相同\n",
    "t5 = torch.tensor(np.arange(12).reshape(3,4))\n",
    "print(t5)\n",
    "print(t5[1,2]) #取值\n",
    "print(t5[1]) #取一行\n",
    "print(t5[:,1]) #取一列\n",
    "print(t5[1:3,1:3]) #取一部分\n",
    "print(t5[1:3,:]) #取一部分\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.279006Z",
     "start_time": "2025-01-18T00:20:44.274352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]], dtype=torch.int32)\n",
      "tensor(6, dtype=torch.int32)\n",
      "tensor([4, 5, 6, 7], dtype=torch.int32)\n",
      "tensor([1, 5, 9], dtype=torch.int32)\n",
      "tensor([[ 5,  6],\n",
      "        [ 9, 10]], dtype=torch.int32)\n",
      "tensor([[ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]], dtype=torch.int32)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": [
    "#两个16行，1列的张量相减，求均值\n",
    "t6 = torch.tensor(np.arange(16).reshape(16,1),dtype=torch.float32)\n",
    "t7 = torch.tensor(np.arange(16,32).reshape(16,1),dtype=torch.float32)\n",
    "print(t6)\n",
    "print(t7)\n",
    "((t6-t7)**2).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.306725Z",
     "start_time": "2025-01-18T00:20:44.298249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.],\n",
      "        [ 1.],\n",
      "        [ 2.],\n",
      "        [ 3.],\n",
      "        [ 4.],\n",
      "        [ 5.],\n",
      "        [ 6.],\n",
      "        [ 7.],\n",
      "        [ 8.],\n",
      "        [ 9.],\n",
      "        [10.],\n",
      "        [11.],\n",
      "        [12.],\n",
      "        [13.],\n",
      "        [14.],\n",
      "        [15.]])\n",
      "tensor([[16.],\n",
      "        [17.],\n",
      "        [18.],\n",
      "        [19.],\n",
      "        [20.],\n",
      "        [21.],\n",
      "        [22.],\n",
      "        [23.],\n",
      "        [24.],\n",
      "        [25.],\n",
      "        [26.],\n",
      "        [27.],\n",
      "        [28.],\n",
      "        [29.],\n",
      "        [30.],\n",
      "        [31.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(256.)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "#初始化两个张量，一个3,4，一个3,1,运算与ndarray相同\n",
    "t8 = torch.tensor(np.arange(12).reshape(3,4),dtype=torch.float32)\n",
    "t9 = torch.tensor(np.arange(3).reshape(3,1),dtype=torch.float32)\n",
    "print(t8)\n",
    "print(t9)\n",
    "t8-t9"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.316127Z",
     "start_time": "2025-01-18T00:20:44.311116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2., 3.],\n",
       "        [3., 4., 5., 6.],\n",
       "        [6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T06:30:45.464008Z",
     "iopub.status.busy": "2022-07-31T06:30:45.463595Z",
     "iopub.status.idle": "2022-07-31T06:30:45.475402Z",
     "shell.execute_reply": "2022-07-31T06:30:45.474425Z",
     "shell.execute_reply.started": "2022-07-31T06:30:45.463971Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.677973Z",
     "start_time": "2025-01-18T00:20:44.329129Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "GPU中tensor的使用：\n",
    "1.实例化device， torch.device(\"cpu\" or \"cuda:0\"),选cuda:0需要torch.cuda.is_available()==true\n",
    "2.tensor.to(device),把tensor转化为CUDA支持的tensor或者CPU支持的tensor\n",
    "\"\"\"\n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") #cuda device对象\n",
    "    y = torch.ones_like(x, device = device) #创建一个在cuda熵的tensor\n",
    "    x = x.to(device) #把x转为cuda上的tensor\n",
    "    z = x+y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))\n",
    "\n",
    "# torch.tensor([1.9806], device = \"cuda:0\")\n",
    "device = torch.device(\"cpu\")\n",
    "x.to(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]], device='cuda:0', dtype=torch.int8)\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1,  0,  1,  2],\n",
       "        [ 3,  4,  5,  6],\n",
       "        [ 7,  8,  9, 10]], dtype=torch.int8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.682006Z",
     "start_time": "2025-01-18T00:20:44.677973Z"
    }
   },
   "source": [
    "# 张量的运算\n",
    "t8 = torch.tensor(np.arange(12).reshape(3,4),dtype=torch.float32)\n",
    "t9 = torch.tensor(np.arange(12).reshape(3,4),dtype=torch.float32)\n",
    "t8*t9"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.,   4.,   9.],\n",
       "        [ 16.,  25.,  36.,  49.],\n",
       "        [ 64.,  81., 100., 121.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": [
    "torch.mm(t8, t9.transpose(0,1)) #矩阵乘法"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T00:20:44.694344Z",
     "start_time": "2025-01-18T00:20:44.683010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 14.,  38.,  62.],\n",
       "        [ 38., 126., 214.],\n",
       "        [ 62., 214., 366.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
